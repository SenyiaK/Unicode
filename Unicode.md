# Unicode

На сегодняшний день почти невозможно представить жизнь современного человека без компьютера. Находясь в разных уголках земного шара, люди могут обмениваться информацией. Обычный человек не догадывается, что используя программы на компьютере он невольно применяет формат преобразования информации. Основа компьютера - это аппаратный комплекс, но для простого пользователя интерес представляют только программы установленные и функционирующие на данном комплексе. Для того, чтобы аппаратные средства смогли передать информацию необходимо её преобразовать в удобный для них формат. Единица хранения информации современных устройств (компьютеров) являются восьмибитные последовательности - байты, т.е. это группа из восьми бит. Бит - это сигнал, который имеет два состояния, понятные для аппаратных средств - выключен или включен и т.д. Для возможности программирования каких-либо состояний бит может принимать значение 0 или 1. 
После прочтения такого заголовка, большинство пользователей вспомнят формат преобразования информации ASCII, т.к. она является наиболее распространенной. 
Данный способ основан на переводе символов (буквы, знаки пунктуации и т.д.) в целые числа, а затем в биты. Этот формат преобразования используется при передаче информации по сети, но если пришло письмо на определенном языке (а в мире их существует достаточно большое количество) будет ли оно корректно отображено?
Для того, чтобы разобраться в данном вопросе вспомним представление данной кодировки. Она содержит содержит 128 символов, т.е. таблица состоит из 128 кодовых точек, что соответствует символам от 0 до 127 включительно. Это требует 7 бит, т.е  ASCII - семибитная кодировка.  
В настоящее время, современная вычислительная техника не использует для хранения информации семибитные последовательности. Разработчиками в такие комплексы было заложено использование восьмибитной последовательности, поэтому использование ASCII нецелесообразно, т.к. остается не задействован еще один бит памяти.
Производились попытки разработки новых способов кодировки, задействующих все восемь бит, но они не могли отобразить все символы, используемые людьми в письменности.  Со временем, была разработана одна большая схема кодировки, которая их объединила - юникод (Unicode).  Unicode содержит 1 114 112 символов, в диапазоне от 0 до 10FFFF. Данные символы поделены на 17 групп, отсчет идет с 0-ой группы.


## Форматы преобразования Unicode

Стандарт Юникода можно представить как номера, которые соответствуют определенным символам и соотношение байт этим номерам.
Номера, которые присваиваются символам - это просто числа. В формате Юникода символы принято отражать в виде U+число. Например: заглавная буква А -U+0410.
Способы представления данных чисел в памяти компьютера или записи в файле - это формы кодирования.
Выделяют несколько форматов преобразования Unicode. Например: UTF-7, UTF-8, UTF-16, UTF-32. В большинстве случаев используются UTF-8 и UTF-16. Разберем суть данных кодировок и выявим их различия в данном пункте.
Основным и главным отличием перечисленных форматов преобразования является способ кодирования символов юникод в байты. Они используют разное количество байтов для представления разных символов. Схожесть этих кодировок заключается в том, что они обе являются кодировками переменной длины.
Сравнение двух форматов приведено в таблице 1.

Таблица 1. Отличие UTF-8 от UTF-16

| Параметры | UTF-8 | UTF-16 |
| ------ | ------ | ------ |
| Количество байт для покрытия всех символов юникода | использует от 1 до 4 байтов на символ | использует 2 байта, либо 4 на символ |
| Сравнение с ASCII | первые 128 символов в таблице юникод совпадают с символами из кодовой таблицы ASCII. Кодировка данных символов происходит одинаково | в данной кодировке символы закодированы двумя байтами |
| Представление одного символа кодировки в BMP | использует от 1 до 3 байтов | использует 2 байта для всех символов базовой многоязычной плоскости (BMP) |

У каждого формата кодирования существует своя таблица, в которой отражено какому символу соответствует определенное число вида  U+число.
Для понимания того, как происходит кодирование символов в данных формат, рассмотрим принципы соответствия чисел и символов в  UTF-8 и UTF-16 более подробно. Это также покажет различие в двух форматах преобразования.


## Принцип кодирования информации UTF-8

Как было описано ранее, вычислительная техника понимает информацию представленную в виде определенной последовательности нулей и единиц. В формате UTF-8 первый бит каждого байта, кодирующего символ, необходим для определения количества отведенных байт под кодировку символа.
Если первый бит нулевой, то для кодирования символа отведен только один байт. Если он не нулевой, то отведено несколько байт под данный символ. 
В формате UTF-8 для двух-байтовых символов, по умолчанию, три бита равны 110, для трех-байтовых - 1110; для четырех-байтовых - 11110. Такие биты называются управляющими. 
```sh
Например:  01001000 - первый бит ноль, значит 1 байт кодирует 1 символ - «H»
```
После того, как определено к какому из четырех видов относится символ, необходимо выполнить следующую последовательность действий, для получения числа закрепленного за символом в таблице формата UTF-8:
- отбрасываем управляющие биты;
- оставшиеся символы переводим в шестнадцатеричный вид.

## Принцип кодирования информации UTF-16

Как отмечалось ранее, все символы базового блока юникода в данном формате кодируются одной кодовой парой (двумя байтами).
```sh
Например:  латинский символ «o» -  00000000 01101111
```
За пределами базового диапазона для кодирования каждого символа используется две кодовые пары - 4 байта. Две кодовые пары принято называть суррогатной парой. Для таких пар в таблице юникода зарезервирован отдельный диапазон (от D800 до DFFF). При переводе числа в шестнадцатеричную систему, можно получить значение попадающее в данный диапазон, что будет означать, что это не самостоятельный символ, а кодовые пары.
Для кодирования символа, не относящегося к базовому диапазону, необходимо выполнить определенные действия, а именно:
- из кода символа вычесть 10000 (шестнадцатиричное) 
- в результате первого пункта будет получено число, которое занимает до 20 бит
ведущие 10 бит из полученного числа суммируются с D800 
- следующие 10 бит суммируются с DC00
- после этого получатся 2 суррогатные пары по 16 бит, первые 6 бит в каждой такой паре отвечают за определение того что это суррогат
- десятый бит в каждом суррогате отвечает за его порядок, если это 1 то это первый суррогат, если 0, то второй
- 
Для того, чтобы расшифровать код необходимо:

- перевести в шестнадцатеричный вид
- проверить попадают ли полученные значения в диапазон суррогатных пар
- если десятый бит (справа) нулевой, то первый суррогат/если десятый бит (справа) единица, значит второй суррогат
- отбросить по 6 бит, отвечающих за определение суррогата
- прибавить 1000
- посмотреть в таблице юникода символ U+полученное значение
Кроме всего перечисленного формат преобразования UTF-16 представлен в двух формах  UTF-16 LE и UTF-16 BE.  BE и LE в названии кодировки указывают на порядок байтов. Отличие UTF-16 LE от UTF-16 заключается в том, что строки всегда получаются закодированными в обратном порядке расположения байтов. В UTF-16 BE прямой порядок расположения байтов.

## Индикация порядка байтов текстового файла

В некоторых текстовых редакторах присутствует возможность выбрать тип кодирования информации. Для определения порядка байтов текстового файла используется специальный юникод-символ (U+FEFF), называемый BOM. Он не является обязательным символом. В ряде источников не рекомендуется использовать эту метку с UTF-8, т.к. некорректно происходит понимание кодировки символов программами.  

## Кодировка и операционная система

В большинстве случаев, на компьютеры устанавливается операционная система Windows или Linux/Unix.  В Windows для байтового представления символов юникод используется UTF-16 LE, в Linux/Unix - UTF-8. При этом Windows не устанавливает ограничение для программ, которые будут установлены поверх нее касательно кодирования текстовых файлов, т.е. программы могут использовать как UTF-16 LE, так и UTF-16 BE. 


